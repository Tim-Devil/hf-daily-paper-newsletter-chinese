{
    "period": "2025-01-14 至 2025-10-30",
    "total_papers": 73,
    "daily_average": 9.12,
    "top_keywords": {
        "模型": 302,
        "生成": 156,
        "推理": 126,
        "语言": 114,
        "数据": 113,
        "训练": 99,
        "视频": 84,
        "摘要": 74,
        "任务": 74,
        "标题": 73,
        "评估": 70,
        "能力": 60,
        "LLMs": 55,
        "过程": 54,
        "性能": 51,
        "图像": 50,
        "实现": 48,
        "文本": 47,
        "显著": 46,
        "语音": 30
    },
    "daily_counts": {
        "2025-01-14": 9,
        "2025-01-15": 10,
        "2025-01-17": 10,
        "2025-01-20": 9,
        "2025-01-21": 1,
        "2025-01-22": 13,
        "2025-01-23": 5,
        "2025-10-30": 16
    },
    "titles": [
        "MiniMax-01：基于闪电注意力机制扩展基础模型",
        "基于指令跟随的多模态AI辅助单细胞分析系统",
        "MangaNinja：基于精确参考跟随的线稿上色",
        "扩散对抗后训练用于一步视频生成",
        "使用紧凑的文本感知一维标记实现文本到图像掩码生成模型的民主化",
        "FramePainter：赋予交互式图像编辑视频扩散先验",
        "PokerBench：训练大型语言模型成为专业扑克玩家",
        "大型语言模型作为非结构化文本数据评判者的潜力与风险",
        "HALoGEN：大型语言模型的幻觉及其发现之处",
        "Tarsier2：从详细视频描述到全面视频理解的大型视觉语言模型进展",
        "超越去噪步长扩展的扩散模型推理时扩展",
        "OmniThink：通过思维扩展机器写作的知识边界",
        "探索高级患者模拟器中的问诊-诊断关系",
        "视觉分词器在重建与生成任务中的规模化探索",
        "RLHS：通过事后模拟缓解RLHF中的错位问题",
        "SynthLight：通过重新渲染合成人脸学习的扩散模型肖像重光照",
        "FAST：面向视觉-语言-动作模型的高效动作标记化方法",
        "迈向大规模推理模型：基于大语言模型的强化推理研究综述",
        "AnyStory：面向文本到图像生成中统一单主体与多主体个性化的研究",
        "CaPa：用于高效4K纹理网格生成的雕刻与绘制合成方法",
        "演化更深层次的LLM思维",
        "PaSa：基于大语言模型的综合性学术论文搜索代理",
        "多项选择题：推理使大型语言模型（LLMs）即使错误时也更为自信",
        "Textoon：基于文本描述生成生动的二维卡通角色",
        "跨越医疗领域的语言障碍：阿拉伯语大语言模型研究",
        "X-Dyna：富有表现力的动态人体图像动画",
        "HiFi-SR：一种用于高保真语音超分辨率的统一生成式Transformer-卷积对抗网络",
        "ComplexFuncBench：探索长上下文场景下的多步和约束函数调用",
        "GaussianAvatar-Editor：可动画化的高斯头部头像编辑器",
        "GameFactory：利用生成式交互视频创建新游戏",
        "MMVU：专家级多学科视频理解评估",
        "Agent-R：通过迭代自训练训练语言模型代理进行反思",
        "Condor：通过知识驱动的数据合成与精炼增强大语言模型对齐",
        "Mobile-Agent-E：面向复杂任务的自进化移动助手",
        "UI-TARS：开创性的自动化GUI交互原生代理",
        "EMO2：基于末端执行器引导的音频驱动虚拟形象视频生成",
        "推理语言模型：一个蓝图",
        "GPS作为图像生成的控制信号",
        "Hunyuan3D 2.0：面向高分辨率纹理3D资产生成的扩散模型扩展",
        "交互学习：现实环境中自适应智能体的数据驱动框架",
        "细节中的魔鬼：在训练专用专家混合模型中实现负载均衡损失的探讨",
        "随流而动：使用实时扭曲噪声实现运动可控的视频扩散模型",
        "视频深度任意：超长视频的一致性深度估计",
        "FilmAgent：虚拟3D空间中端到端电影自动化的多智能体框架",
        "DeepSeek-R1：通过强化学习激励大语言模型的推理能力",
        "专家自主模型",
        "Kimi k1.5：利用大语言模型扩展强化学习",
        "O1-Pruner：用于O1类推理剪枝的长度协调微调",
        "Video-Thinker：通过强化学习实现“视频思维”的突破",
        "JanusCoder：构建面向代码智能的基础视觉-编程交互框架",
        "RegionE：面向高效图像编辑的自适应区域感知生成框架",
        "基于循环语言模型的潜在推理规模化研究",
        "工具十项全能：面向多样化、真实化及长周期任务执行的语言智能体基准测试",
        "基于过程挖掘的推理感知型GRPO方法研究",
        "VFXMaster：通过上下文学习解锁动态视觉特效生成",
        "ReForm：基于前瞻有界序列优化的反射式自动形式化方法",
        "将驾驶世界模型重新构想为感知任务的合成数据生成器",
        "并行循环Transformer：高效测试时计算扩展",
        "MASPRM：多智能体系统过程奖励模型",
        "明闪万象：面向多模态感知与生成的稀疏统一架构",
        "SeeingEye：基于智能体信息流解锁纯文本大语言模型的多模态推理能力",
        "TheraMind：面向纵向心理咨询的战略性自适应智能体",
        "PairUni：面向统一多模态语言模型的成对训练方法",
        "BhashaBench V1：印度知识象限领域的综合性基准测试框架"
    ]
}